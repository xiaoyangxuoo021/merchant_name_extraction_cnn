{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedmerchants = pd.read_csv('data/cleanedmerchant_training.csv')\n",
    "len(cleanedmerchants[cleanedmerchants['ds_mid']==0]) / len(cleanedmerchants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmapped = cleanedmerchants[cleanedmerchants['ds_mid']==0]\n",
    "\n",
    "from nltk import word_tokenize\n",
    "raw_docs = unmapped['merchant_name'].to_list()\n",
    "tokenized_docs = [word_tokenize(doc) for doc in raw_docs if isinstance(doc, str)]\n",
    "len(tokenized_docs) + 1 == len(raw_docs)\n",
    "# #all(isinstance(x, str) for x in raw_docs)\n",
    "# for doc in raw_docs:\n",
    "#     if not isinstance(doc, str):\n",
    "#         print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unmapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "states.extend([string.lower() for string in states])\n",
    "states.append('us')\n",
    "states.append('US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "list_of_words_all = [item for sublist in tokenized_docs for item in sublist]\n",
    "list_of_words = [word for word in list_of_words_all if word not in stopwords.words('english') and word not in states]\n",
    "from collections import Counter\n",
    "ctr = Counter(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "most_common = ctr.most_common(100)\n",
    "# most_common\n",
    "x = range(0, len(most_common))\n",
    "y = [most_common[i][1] for i in range(len(most_common))]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonword_removed_docs = [doc for doc in tokenized_docs if len(set(doc).intersection(common_words)) < 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355760\n",
      "395283\n"
     ]
    }
   ],
   "source": [
    "print(len(commonword_removed_docs))\n",
    "print(len(tokenized_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list(commonword_removed_docs)\n",
    "with open('words.txt', 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(' '.join(line))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a pipeline and create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"LOWER\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.strings.add(\"coffee\")\n",
    "coffee_hash = nlp.vocab.strings[\"coffee\"]\n",
    "coffee_string = nlp.vocab.strings[coffee_hash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "# The words and spaces to create the doc from\n",
    "words = [\"Hello\", \"world\", \"!\"]\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a doc manually\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "# Create a span manually\n",
    "span = Span(doc, 0, 2)\n",
    "\n",
    "# Create a span with a label\n",
    "span_with_label = Span(doc, 0, 2, label=\"GREETING\")\n",
    "\n",
    "# Add span to the doc.ents\n",
    "doc.ents = [span_with_label]\n",
    "for ent in doc.ents:\n",
    "    print(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# spacy.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Compare two documents\n",
    "doc1 = nlp(\"I like fast food and fried chicken\")\n",
    "token1 = doc1[2:4]\n",
    "token2 = doc1[5:6]\n",
    "\n",
    "print(token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "import json\n",
    "\n",
    "# with open(\"exercises/en/countries.json\", encoding=\"utf8\") as f:\n",
    "#     COUNTRIES = json.loads(f.read())\n",
    "# with open(\"exercises/en/country_text.txt\", encoding=\"utf8\") as f:\n",
    "#     TEXT = f.read()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "patterns = list(nlp.pipe(COUNTRIES))\n",
    "matcher.add(\"COUNTRY\", patterns)\n",
    "\n",
    "# Create a doc and reset existing entities\n",
    "doc = nlp(TEXT)\n",
    "doc.ents = []\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matcher(doc):\n",
    "    # Create a Span with the label for \"GPE\"\n",
    "    span = Span(doc, start, end, label=\"GPE\")\n",
    "\n",
    "    # Overwrite the doc.ents and add the span\n",
    "    doc.ents = list(doc.ents) + [span]\n",
    "\n",
    "    # Get the span's root head token\n",
    "    span_root_head = span.root.head\n",
    "    # Print the text of the span root's head token and the span text\n",
    "    print(span_root_head.text, \"-->\", span.text)\n",
    "\n",
    "# Print the entities in the document\n",
    "print([(ent.text, ent.label_) for ent in doc.ents if ent.label_ == \"GPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\n",
    "    \"Twitch Prime, the perks program for Amazon Prime members offering free \"\n",
    "    \"loot, games and other benefits, is ditching one of its best features: \"\n",
    "    \"ad-free viewing. According to an email sent out to Amazon Prime members \"\n",
    "    \"today, ad-free viewing will no longer be included as a part of Twitch \"\n",
    "    \"Prime for new members, beginning on September 14. However, members with \"\n",
    "    \"existing annual subscriptions will be able to continue to enjoy ad-free \"\n",
    "    \"viewing until their subscription comes up for renewal. Those with \"\n",
    "    \"monthly subscriptions will have access to ad-free viewing until October 15.\"\n",
    ")\n",
    "\n",
    "# Create the match patterns\n",
    "pattern1 = [{\"LOWER\": \"amazon\"}, {\"POS\": \"PROPN\"}]\n",
    "pattern2 = [{\"LOWER\": \"ad\"}, {\"TEXT\": \"-\"}, {\"LOWER\": \"free\"}, {\"POS\": \"NOUN\"}]\n",
    "\n",
    "# Initialize the Matcher and add the patterns\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"PATTERN1\", [pattern1])\n",
    "matcher.add(\"PATTERN2\", [pattern2])\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matcher(doc):\n",
    "    # Print pattern string name and text of matched span\n",
    "    print(doc.vocab.strings[match_id], doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### method extension on the Doc or span objects, the first argument is equivalent to \"self\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "\n",
    "# Define method with arguments\n",
    "def has_token(doc, token_text):\n",
    "    in_doc = token_text in [token.text for token in doc]\n",
    "    return in_doc\n",
    "\n",
    "# Set extension on the Doc with method\n",
    "Doc.set_extension(\"has_token\", method=has_token)\n",
    "\n",
    "doc = nlp(\"The sky is blue.\")\n",
    "print(doc._.has_token(\"blue\"), \"- blue\")\n",
    "print(doc._.has_token(\"cloud\"), \"- cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom pipeline components with added doc attribute/method extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "with open(\"exercises/en/countries.json\", encoding=\"utf8\") as f:\n",
    "    COUNTRIES = json.loads(f.read())\n",
    "\n",
    "with open(\"exercises/en/capitals.json\", encoding=\"utf8\") as f:\n",
    "    CAPITALS = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"COUNTRY\", list(nlp.pipe(COUNTRIES)))\n",
    "\n",
    "\n",
    "@Language.component(\"countries_component\")\n",
    "def countries_component_function(doc):\n",
    "    # Create an entity Span with the label \"GPE\" for all matches\n",
    "    matches = matcher(doc)\n",
    "    doc.ents = [Span(doc, start, end, label=\"GPE\") for match_id, start, end in matches]\n",
    "    return doc\n",
    "\n",
    "\n",
    "# Add the component to the pipeline\n",
    "nlp.add_pipe(\"countries_component\")\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Getter that looks up the span text in the dictionary of country capitals\n",
    "get_capital = lambda span: CAPITALS.get(span.text)\n",
    "\n",
    "# Register the Span extension attribute \"capital\" with the getter get_capital\n",
    "Span.set_extension(\"capital\", getter=get_capital)\n",
    "\n",
    "# Process the text and print the entity text, label and capital attributes\n",
    "doc = nlp(\"Czech Republic may help Slovakia protect its airspace\")\n",
    "print([(ent.text, ent.label_, ent._.capital) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scleandataset = pd.read_csv('data/dataset.csv')\n",
    "cleandataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip the below two cells if you have shuffled_dataset in data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from random import shuffle\n",
    "\n",
    "shuffle_1 = cleandataset.copy()\n",
    "shuffle_2 = cleandataset.copy()\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "# shuffle_1['merchant_name'] = shuffle_1['merchant_name'].apply(lambda sentence: ' '.join(random.sample(sentence.split(' '), k = len(sentence.split(' ')))))\n",
    "# # shuffle_1.head()\n",
    "# shuffle_2['merchant_name'] = shuffle_2['merchant_name'].apply(lambda sentence: ' '.join(random.sample(sentence.split(' '), k = len(sentence.split(' ')))))\n",
    "# shuffle_2.sample(5)\n",
    "for idx, row in shuffle_1.iterrows():\n",
    "    if len(row[1].split()) > 1:\n",
    "        try:\n",
    "            sidx = row[0].find(row[1])\n",
    "            eidx = sidx + len(row[1])\n",
    "            merchant = row[1]\n",
    "            tempsentence = row[0][:]\n",
    "            insertion_pos = tempsentence.split().index(merchant.split()[0])\n",
    "            tempsentence_removed_tokenized = tempsentence.replace(row[1], ' ').split()\n",
    "            tempsentence_removed_tokenized.insert(insertion_pos, merchant)\n",
    "            shuffled_sentence = ' '.join(random.sample(tempsentence_removed_tokenized, k = len(tempsentence_removed_tokenized)))\n",
    "            shuffle_1.iloc[idx, 0] = shuffled_sentence\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        shuffle_1.iloc[idx, 0] = ' '.join(random.sample(row[0].split(' '), k = len(row[0].split(' '))))\n",
    "\n",
    "shuffle_1.reset_index(drop = True)\n",
    "for idx, row in shuffle_1.iterrows():\n",
    "    shuffle_1.iloc[idx, 2] = shuffle_1.iloc[idx, 0].find(shuffle_1.iloc[idx, 1])\n",
    "    shuffle_1.iloc[idx, 3] = shuffle_1.iloc[idx, 2] + len(shuffle_1.iloc[idx, 1])\n",
    "shuffle_1.sample(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in shuffle_2.iterrows():\n",
    "    if len(row[1].split()) > 1:\n",
    "        try:\n",
    "            sidx = row[0].find(row[1])\n",
    "            eidx = sidx + len(row[1])\n",
    "            merchant = row[1]\n",
    "            tempsentence = row[0][:]\n",
    "            insertion_pos = tempsentence.split().index(merchant.split()[0])\n",
    "            tempsentence_removed_tokenized = tempsentence.replace(row[1], ' ').split()\n",
    "            tempsentence_removed_tokenized.insert(insertion_pos, merchant)\n",
    "            shuffled_sentence = ' '.join(random.sample(tempsentence_removed_tokenized, k = len(tempsentence_removed_tokenized)))\n",
    "            shuffle_2.iloc[idx, 0] = shuffled_sentence\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        shuffle_2.iloc[idx, 0] = ' '.join(random.sample(row[0].split(' '), k = len(row[0].split(' '))))\n",
    "\n",
    "shuffle_2.reset_index(drop = True)\n",
    "for idx, row in shuffle_2.iterrows():\n",
    "    shuffle_2.iloc[idx, 2] = shuffle_2.iloc[idx, 0].find(shuffle_2.iloc[idx, 1])\n",
    "    shuffle_2.iloc[idx, 3] = shuffle_2.iloc[idx, 2] + len(shuffle_2.iloc[idx, 1])\n",
    "shuffle_2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_temp = pd.concat([cleandataset, shuffle_1], axis = 0)\n",
    "result = pd.concat([result_temp, shuffle_2], axis = 0)\n",
    "result.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('data/shuffled_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvb = pd.read_csv('data/mvb_cleanedmerchant_training_fourbanks.csv', on_bad_lines = 'warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('data/shuffled_dataset.csv')\n",
    "if 'Unnamed: 0' in result.columns:\n",
    "    result.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "    \n",
    "TRAIN_DATA = result.values.tolist()\n",
    "#TRAIN_DATA = [(item[0], {'merchant': item[1], 'entities':[(item[2], item[3], 'BRD')]}) for item in TRAIN_DATA]\n",
    "TRAIN_DATA = [(item[0], {'entities':[(item[2], item[3], 'BRD')]}) for item in TRAIN_DATA]\n",
    "TRAIN_DATA[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from random import sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.gold import GoldParse\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def train_spacy(data,iterations):\n",
    "    TRAIN_DATA = data\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            batches = minibatch(TRAIN_DATA, size = compounding(4, 32, 1.001))\n",
    "            for batch in batches:\n",
    "                text, annotations = zip(*batch)\n",
    "                # text = nlp.make_doc(text)    #<--- add this\n",
    "                # gold = GoldParse(text, entities=annotations)  #<--- add this\n",
    "                nlp.update(\n",
    "                    text,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    sgd = optimizer,  # callable to update weights\n",
    "                    drop = 0.35,\n",
    "                    losses=losses)\n",
    "            print(losses)\n",
    "    return nlp\n",
    "\n",
    "random.shuffle(TRAIN_DATA)\n",
    "\n",
    "train = TRAIN_DATA[:int(len(TRAIN_DATA) *0.07)]\n",
    "test = TRAIN_DATA[int(len(TRAIN_DATA) *0.07):]\n",
    "\n",
    "prdnlp = train_spacy(train, 100)\n",
    "# Save our trained Model\n",
    "modelfile = 'wtf_3_100_epoch'\n",
    "prdnlp.to_disk(modelfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the trained pipeline into a .tar.gz package\n",
    "!python -m spacy package wtf_2 ./packages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generation of a  config\n",
    "!python -m spacy init config ./config.cfg --lang en --pipeline ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# from spacy.tokens import Span\n",
    "# nlp = spacy.blank(\"en\")\n",
    "# doc3 = nlp(\"There's also a Paris in Arkansas, lol\")\n",
    "# for ent in doc3.ents:\n",
    "#     print(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = TRAIN_DATA[int(len(TRAIN_DATA) *0.07):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test your text\n",
    "\n",
    "TESTDATA = result.values.tolist()\n",
    "TESTDATA = [(item[0], {'merchant': item[1], 'entities':[(item[2], item[3], 'BRD')]}) for item in TESTDATA]\n",
    "test = TESTDATA[int(len(TESTDATA) *0.07):]\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "test_text = sample(test, 1000)\n",
    "scores = []\n",
    "for text in test_text:\n",
    "    #print('test case: ', text)\n",
    "    doc = prdnlp(text[0])\n",
    "    for ent in doc.ents:\n",
    "        # print(ent.text)\n",
    "        # print('True label is: ')\n",
    "        # print(text[1]['merchant'])\n",
    "        similarity = fuzz.token_set_ratio(ent.text,text[1]['merchant'])\n",
    "        #print('similarity is: ', similarity)\n",
    "        scores.append(similarity)\n",
    "print(scores.count(100) / len(scores) *100, ' percent of test data has been perfectly correctly classified.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_nlp = spacy.load('wtf_2')\n",
    "test_text = sample(test, 10)\n",
    "for text in test_text:\n",
    "    print('test case: ', text)\n",
    "    doc = load_nlp(text[0])\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = load_nlp('brother s 3659 nebrask')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdata = pd.read_csv('data/cleanedmerchant_training.csv') ## read the file into to a pandas dataframe\n",
    "data = tempdata[['merchant_name', 'cleanName2']]\n",
    "invalidName = data[data['cleanName2'].isnull()]\n",
    "invalidName.reset_index(inplace=True, drop = True)\n",
    "invalidName.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# mu, sigma = 100, 10 # mean and standard deviation\n",
    "# s = np.random.normal(mu, sigma, 1000)\n",
    "# s_2 = np.random.uniform(70, 130, 1000)\n",
    "\n",
    "# count, bins, ignored = plt.hist(s, 30, density=False, color = 'r')\n",
    "# # plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "# #                np.exp( - (bins - mu)**2 / (2 * sigma**2) )\n",
    "# #          )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_docs = [\"Here are some very simple basic sentences.\",\n",
    "# \"They won't be very interesting, I'm afraid.\",\n",
    "# \"The point of these examples is to _learn how basic text cleaning works_ on *very simple* data.\"]\n",
    "raw_docs = validName['merchant_name'].to_list()\n",
    "tokenized_docs = [word_tokenize(doc) for doc in raw_docs]\n",
    "print(tokenized_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation)) #see documentation here: http://docs.python.org/2/library/string.html\n",
    "\n",
    "tokenized_docs_no_punctuation = []\n",
    "\n",
    "for review in tokenized_docs:\n",
    "    new_review = []\n",
    "    for token in review:\n",
    "        new_token = regex.sub(u'', token)\n",
    "        if not new_token == u'':\n",
    "            new_review.append(new_token)\n",
    "    \n",
    "    tokenized_docs_no_punctuation.append(new_review)\n",
    "    \n",
    "print(tokenized_docs_no_punctuation[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'def', 'def', 'dasdsa'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenized_docs_no_stopwords = []\n",
    "\n",
    "for doc in tokenized_docs_no_punctuation:\n",
    "    new_term_vector = []\n",
    "    for word in doc:\n",
    "        if not word in stopwords.words('english'):\n",
    "            new_term_vector.append(word)\n",
    "    \n",
    "    tokenized_docs_no_stopwords.append(new_term_vector)\n",
    "\n",
    "print(tokenized_docs_no_stopwords[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentences = [' '.join(words) for words in tokenized_docs_no_stopwords]\n",
    "len(cleaned_sentences) == len(validName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validName['merchant_name'] = cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Shuffle samples in dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: (list) list of tuples like: [(transaction, start_idx, end_idx), ..... , ]\n",
    "\n",
    "    Returns:\n",
    "        dataset: (list) list of tuples like: [,....., (transaction, start_idx, end_idx), ..... , ]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    shuffled_indices = list(range(len(dataset)))\n",
    "    random.shuffle(shuffled_indices)\n",
    "    dataset = [dataset[index] for index in shuffled_indices]\n",
    "\n",
    "    return dataset\n",
    "def get_merchant_indices_in_sentence(sentence, merchant):\n",
    "    \"\"\"\n",
    "    Given transaction string and merchant string, returns start end end indices of merchant in transaction string.\n",
    "\n",
    "    Args:\n",
    "        sentence: (string) transaction string. (example: )\n",
    "        merchant: (string) merchant name. (example: )\n",
    "\n",
    "    Returns:\n",
    "        sentence: (string) converted to upper strings\n",
    "        start: (int) merchant string start index\n",
    "        end: (int) merchant string end index\n",
    "\n",
    "    Examples:\n",
    "        sentences, start, end = get_sentence_indices(\"Target 00014423 WATERTOWN MA\",\"target\")\n",
    "\n",
    "        sentences: \"TARGET 00014423 WATERTOWN MA\"\n",
    "        start: 0\n",
    "        end: 6\n",
    "    \"\"\"\n",
    "\n",
    "    sentence = sentence.upper()\n",
    "    merchant = merchant.upper()\n",
    "\n",
    "    start = -1\n",
    "    end = -1\n",
    "\n",
    "    idx = sentence.find(merchant)\n",
    "    if idx != -1:\n",
    "        start = idx\n",
    "        end = start + len(merchant)\n",
    "\n",
    "    return sentence, start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validName.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for idx, row in validName.iterrows():\n",
    "    # print('Processing row: ', idx)\n",
    "    # print('row0: ', row[0])\n",
    "    # print('row1: ', row[1])\n",
    "    # print(row[0].find(row[1].split(' ')[0]))\n",
    "    # print(len(row[1]))\n",
    "    find_i = row[0].find(row[1].split(' ')[0])\n",
    "    if find_i + len(row[1]) > len(row[0]):   \n",
    "        row[0] = row[0][:find_i] + row[1]\n",
    "    \n",
    "    sentence, start, end = get_merchant_indices_in_sentence(row[0], row[1])\n",
    "    validName.loc[idx, 'start_idx'] = start\n",
    "    validName.loc[idx, 'end_idx'] = end\n",
    "\n",
    "print(validName.sample(50))\n",
    "#validName.to_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validName.to_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandataset = cleandataset.drop(columns = 'Unnamed: 0')\n",
    "cleandataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandataset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandataset = cleandataset[cleandataset['start_idx']!=-1]\n",
    "len(cleandataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleandataset.to_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_embedding(text, max_len=300, emb_dim=8):\n",
    "        \"\"\"\n",
    "        Embeds character string with the use of (emb_dim)-bit binary values of each character.\n",
    "\n",
    "        Args:\n",
    "            text: (string) text to embed\n",
    "            max_len: (int) maximum length of text that will be encoded. Padding will be done with zeros.\n",
    "            emb_dim:\n",
    "\n",
    "        Returns:\n",
    "            str_array: (ndarray) 2 dimensional numpy array containing embedded text of shape emb_dim*max_len\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # cut long text with maximum accepted length\n",
    "        if len(text) > max_len:\n",
    "            text = text[:max_len]\n",
    "\n",
    "        str_array = np.zeros((emb_dim, max(len(text), max_len)), dtype=np.int32).tolist()\n",
    "\n",
    "        for index, char in enumerate(text):\n",
    "            str_binary = format(ord(char), 'b').zfill(emb_dim)[::-1]\n",
    "            str_binary = str_binary[:emb_dim]\n",
    "            for str_index, str_char in enumerate(str_binary, 0):\n",
    "                str_array[str_index][index] = int(str_char)\n",
    "       \n",
    "        padding_str_binary = '0' * emb_dim\n",
    "        \n",
    "        for index in range(len(text), max_len):\n",
    "            for str_index, str_char in enumerate(padding_str_binary, 0):\n",
    "                str_array[str_index][index] = int(str_char)\n",
    "\n",
    "        return str_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "emb = character_embedding('Martin')\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleandataset.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df[:int(0.7 * len(df))]\n",
    "val_dataset = df[int(0.7 * len(df)): int(0.85 * len(df))]\n",
    "test_dataset = df[int(0.85 * len(df)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n",
    "matcher.add(\"sID\", [pattern])\n",
    "\n",
    "doc = nlp(\"Hello, world! Hello world!\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"dollar general w main a\")\n",
    "print(doc.ents)\n",
    "# for idx, row in sample_10.iterrows():\n",
    "#     # print('processing row: ', idx)\n",
    "#     # print(row[0])\n",
    "#     doc = nlp(row[0])\n",
    "#     all_entities = doc.ents\n",
    "#     print(all_entities)\n",
    "#     # print(all_entities)\n",
    "#     #extraction_temp = str(process.extractOne(row[1], all_entities)[0])\n",
    "#     #extraction =  re.sub(r\"inc|mktp|\\d+\", \"\", extraction_temp) \n",
    "#     #print('extraction result: ', extraction_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cleanData = pd.read_csv('data/cleanedmerchant_training.csv')\n",
    "cleanData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwordFreeds[(stopwordFreeds['cleanName2'] != stopwordFreeds['CleanName3']) & (stopwordFreeds['CleanName3'] != 'chick fil')].sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
